{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "__author__ = 'nadya_motina'\n",
    "\n",
    "import time\n",
    "import codecs\n",
    "import pandas\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from gensim.models import Word2Vec\n",
    "from itertools import combinations\n",
    "from transliterate import translit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_word(i, data):\n",
    "    # extracts necessary data from the table and make a readable word for word2vec model\n",
    "    # input: index, table\n",
    "    # output: \"word_S\"\n",
    "    pos = data['PoS'][i]\n",
    "    ipm = float(data['Freq(ipm)'][i])\n",
    "    lemma = (data['Lemma'][i] + '_' + pos.upper()).decode('utf8')\n",
    "    return lemma\n",
    "\n",
    "def build_rng(word, model, topn=10):\n",
    "    # 1) find N most similar words from the model\n",
    "    # 2) for each combination of 2 words find if there is some other neighbor in between them\n",
    "    #    * if there is no such word: add an edge\n",
    "    # output: graph object\n",
    "    wg = nx.DiGraph()\n",
    "    neighbors = model.most_similar(word, topn=topn)\n",
    "    neighbors.append((word, 1.0))\n",
    "    for pair in combinations(neighbors, 2):\n",
    "        word0 = pair[0][0]\n",
    "        word1 = pair[1][0]\n",
    "        similarity = model.similarity(word0, word1)\n",
    "        if similarity > 0:\n",
    "            remaining = [vertex for vertex in neighbors if vertex != pair[0] \\\n",
    "                         and vertex != pair[1]]\n",
    "            for vertex in remaining:\n",
    "                drawedge = True\n",
    "                candidate = vertex[0]\n",
    "                if model.similarity(candidate, word1) > similarity \\\n",
    "                and model.similarity(candidate, word0) > similarity:\n",
    "                    drawedge = False\n",
    "                    break\n",
    "                if drawedge == True:\n",
    "                    w1 = translit(pair[0][0], 'ru', reversed=True) \n",
    "                    w2 = translit(pair[1][0], 'ru', reversed=True)\n",
    "                    wg.add_edge(w1, w2)#, cos_sim=similarity)\n",
    "    return wg.to_undirected(), translit(word, 'ru', reversed=True)\n",
    " \n",
    "def draw_rng(wg):\n",
    "    print nx.info(wg)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.axis('off')\n",
    "    pos = nx.circular_layout(wg)\n",
    "    nx.draw_networkx(wg, pos=pos, with_labels=True, node_size=100 ,font_size=16,\\\n",
    "                     node_shape='o', alpha=0.3, node_color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully. It took  15.6495559216  seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = Word2Vec.load_word2vec_format('../../Diplom/models/ruscorpora.model.bin', binary=True)\n",
    "print 'Model loaded successfully. It took ', time.time() - start_time, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>PoS</th>\n",
       "      <th>Freq(ipm)</th>\n",
       "      <th>Doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>быть</td>\n",
       "      <td>v</td>\n",
       "      <td>12160.7</td>\n",
       "      <td>34184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>год</td>\n",
       "      <td>s</td>\n",
       "      <td>3727.5</td>\n",
       "      <td>29477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>мочь</td>\n",
       "      <td>v</td>\n",
       "      <td>2912.3</td>\n",
       "      <td>25413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>человек</td>\n",
       "      <td>s</td>\n",
       "      <td>2723.0</td>\n",
       "      <td>20423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>сказать</td>\n",
       "      <td>v</td>\n",
       "      <td>2396.6</td>\n",
       "      <td>15426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Lemma PoS  Freq(ipm)    Doc\n",
       "0     быть   v    12160.7  34184\n",
       "1      год   s     3727.5  29477\n",
       "2     мочь   v     2912.3  25413\n",
       "3  человек   s     2723.0  20423\n",
       "4  сказать   v     2396.6  15426"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infile = codecs.open('../Lyashevskaya/freqrnc2011.csv', 'r', 'utf8')\n",
    "data = pandas.read_csv(infile, sep='\\t')\n",
    "infile.close()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь**\n",
    "1. для начала для каждого слова из словаря найти ближайшие k соседей с помощью most_similar (пусть 100) и сохранить в список.\n",
    "2. затем из каждого такого списка построить свой RNG\n",
    "3. путем анализа таких RNG определять - сколько значений у данного слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "u\"word '\\u043c\\u0438\\u0440_N' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-bf0e418beb93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'мир_N'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdraw_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# nx.write_graphml(graph, \"test.graphml\", encoding='utf-8')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-cec1db8db453>\u001b[0m in \u001b[0;36mbuild_rng\u001b[0;34m(word, model, topn)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# output: graph object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mwg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thatdau/anaconda/lib/python2.7/site-packages/gensim-0.12.2-py2.7-macosx-10.5-x86_64.egg/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot compute similarity with no input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: u\"word '\\u043c\\u0438\\u0440_N' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "graph, node = build_rng('мир_N'.decode('utf8'), model, topn=100)\n",
    "draw_rng(graph)\n",
    "# nx.write_graphml(graph, \"test.graphml\", encoding='utf-8')\n",
    "print nx.clustering(graph)[node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = {}\n",
    "\n",
    "for i in range(100):\n",
    "    word = process_word(i, data)\n",
    "    try:\n",
    "        wg, node = build_rng(word, model, topn=100)\n",
    "        #connectivity = nx.average_node_connectivity(wg)\n",
    "        features[word] = nx.clustering(wg)[node]\n",
    "    except: # Word not in model\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show word-graphs with **high clustering** of the initial word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вопрос_S \t0.600308641975\n",
      "час_S \t0.574565883555\n",
      "русский_A \t0.585225225225\n",
      "земля_S \t0.580028666985\n",
      "спросить_V \t0.73281075028\n",
      "последний_A \t0.656438969765\n",
      "стоить_V \t0.554341736695\n",
      "жизнь_S \t0.557337610265\n",
      "часть_S \t0.611717171717\n",
      "считать_V \t0.704591265398\n"
     ]
    }
   ],
   "source": [
    "for i in features:\n",
    "    c = features[i]\n",
    "    if c >= 0.55:\n",
    "        print i, '\\t', c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show word-graphs with **low clustering** of the initial word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сидеть_V \t0.226666666667\n",
      "глаз_S \t0.243258749283\n",
      "высокий_A \t0.206625258799\n",
      "друг_S \t0.123563218391\n",
      "жить_V \t0.248013090229\n",
      "слово_S \t0.179964539007\n",
      "увидеть_V \t0.199195171026\n",
      "конец_S \t0.180774032459\n",
      "голова_S \t0.243677375256\n",
      "машина_S \t0.147147147147\n",
      "право_S \t0.195378631892\n",
      "женщина_S \t0.177777777778\n"
     ]
    }
   ],
   "source": [
    "for i in features:\n",
    "    c = features[i]\n",
    "    if c < 0.25:\n",
    "        print i, '\\t', c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
